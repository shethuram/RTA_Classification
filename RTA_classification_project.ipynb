{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_mhTdLGtnBM"
      },
      "outputs": [],
      "source": [
        "!pip install category_encoders\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77517yPBpaAm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.impute import KNNImputer\n",
        "import category_encoders as ce\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import RobustScaler,MinMaxScaler,StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import optuna\n",
        "\n",
        "pd.set_option('display.max_columns', None)  # will display all columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGeUgT0ZqIHD"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/RTA Dataset.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfqNFgPvqQ_t"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2CXo4Ctq3nF"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GO6fu4fj1IZr"
      },
      "outputs": [],
      "source": [
        "data['Accident_severity'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4ffi9Bor2XF"
      },
      "source": [
        "# **CONVERTING THE DATA TYPES**\n",
        "\n",
        "1. Time column - object to datetime datatype\n",
        "2. All other object columns to category datatype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiJjMeCDq-vF"
      },
      "outputs": [],
      "source": [
        "data['Time'] = pd.to_datetime(data['Time'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGZGeqbprveF"
      },
      "outputs": [],
      "source": [
        "object_columns = data.select_dtypes(include='object').columns\n",
        "object_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qv6zohZFrzFw"
      },
      "outputs": [],
      "source": [
        "for col in object_columns:\n",
        "  data[col] = data[col].astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuGcUnV0XvNi"
      },
      "outputs": [],
      "source": [
        "data['Casualty_class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TEAGNBfsahb"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtmF5W5hv_xZ"
      },
      "source": [
        "# **DUPILICATES AND DESCRIPTIONS**\n",
        "\n",
        "1.Check for duplicates - if so remove them\n",
        "\n",
        "2.Know the decriptions for both numerical and categorical values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptgVqKg6scDL"
      },
      "outputs": [],
      "source": [
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6WHRMqEwc3T"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AILaibVawl55"
      },
      "outputs": [],
      "source": [
        "data.describe(include = 'category')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY51ISe8xKFV"
      },
      "source": [
        "**GRAPHS**\n",
        "\n",
        "# **UNIVARIATE**\n",
        "\n",
        "---\n",
        "1.Numerical - hist, box\n",
        "\n",
        "2.Categorical - count\n",
        "\n",
        "3.datetime - extract numeric - hist , box\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pReVUjuiZCg"
      },
      "outputs": [],
      "source": [
        "data['Hour'] = data['Time'].dt.hour   # created a new column that has the HOUR at which accidents happend\n",
        "data.drop('Time', axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blzjnlZAZlZu"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHKWlmmxykxb"
      },
      "outputs": [],
      "source": [
        "numerical_columns = ['Number_of_vehicles_involved',\t'Number_of_casualties', 'Hour' ]\n",
        "category_cols= object_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXUCWL1hyrMA"
      },
      "outputs": [],
      "source": [
        "def plot_numeric(col):\n",
        "  sns.histplot(data=data,x=col)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEiTi8Y5yuRB"
      },
      "outputs": [],
      "source": [
        "for col in numerical_columns:\n",
        "  plot_numeric(col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj4nathry9RT"
      },
      "source": [
        "**INFERANCES**\n",
        "\n",
        "Graph - 1\n",
        "\n",
        "*   Involvement of **Two vehicles** is the maximum and **Five** being the minimum\n",
        "\n",
        "Graph - 2\n",
        "\n",
        "*   **One** casuality is the maximum and **Eight** is the minimum\n",
        "\n",
        "Graph - 3\n",
        "\n",
        "*  Most of the accidents happend around **12 to 18 hrs and 17** being the maximum\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sjwUf8wyxKn"
      },
      "outputs": [],
      "source": [
        "def plot_numeric(col):\n",
        "  sns.boxplot(data=data,y=col)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Q2OGrQMYiGE"
      },
      "outputs": [],
      "source": [
        "for col in numerical_columns:\n",
        "  plot_numeric(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0B_BtpOYkvx"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=data,x='Work_of_casuality')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aBwdPu7a45m"
      },
      "source": [
        "**INFERANCE**\n",
        "\n",
        "Drivers are most affected by accidents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tdd3p_LVatyO"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=data,x='Sex_of_driver')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04uErXxKb10N"
      },
      "source": [
        "**INFERANCE**\n",
        "\n",
        "Male gender causes most of the accidents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVUr6aGhfWAx"
      },
      "source": [
        "# **BIVARIATE**\n",
        "\n",
        "---\n",
        "1.Numeric vs Target - numeric vs category - count(if range is too small),box\n",
        "\n",
        "2.Category vs Target - category vs category - count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvidMId-bzDM"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x='Accident_severity', y='Number_of_vehicles_involved', data=data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbWZy6m5cuFt"
      },
      "source": [
        "**INFERANCE**\n",
        "\n",
        "* Fatal,Serious injuries happen when very less number of vehicles involved\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5ujfzYzcoZD"
      },
      "outputs": [],
      "source": [
        "sns.countplot(hue='Accident_severity', x='Number_of_vehicles_involved', data=data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1zKDNBEemli"
      },
      "source": [
        "**INFERANCE**\n",
        "\n",
        "The Accident severity is maximum when **Two vehicles** are involved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLRTtgAleYEv"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x='Work_of_casuality', hue='Accident_severity', data=data)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XyNuAL3gW8n"
      },
      "source": [
        "# **MULTIVARIATE**\n",
        "\n",
        "* Heatmap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJqbAoPQk1BH"
      },
      "outputs": [],
      "source": [
        "corr = data[numerical_columns].corr()\n",
        "corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmot54IxgGmi"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "sns.heatmap(corr, cmap='RdBu_r', annot=True, vmax=1, vmin=-1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zBcfoG5bu7Y"
      },
      "source": [
        "# analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoxOyg87kRMS"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jYqGT4jdXCr"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "y = data['Accident_severity']\n",
        "X = data.drop('Accident_severity' , axis = 1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOherXRrfAb_"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QW3ZW710fJxb"
      },
      "outputs": [],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJaaY6oRfL6R"
      },
      "outputs": [],
      "source": [
        "X_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5Xuyaj8flfv"
      },
      "outputs": [],
      "source": [
        "X_test.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeIrFMvLsoPY"
      },
      "outputs": [],
      "source": [
        "X_train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e36Hpi5b-ym9"
      },
      "source": [
        "# **MISSING VALUE HANDLING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7oaRCuSDk4Z"
      },
      "outputs": [],
      "source": [
        "p = 9852*0.8\n",
        "p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3Q4s-Utfw4f"
      },
      "outputs": [],
      "source": [
        "X_train.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hotC6zR4D-gP"
      },
      "outputs": [],
      "source": [
        "q = 2464*0.8\n",
        "q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69qzg7W4gF24"
      },
      "outputs": [],
      "source": [
        "X_test.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwVn1ZK7gWCM"
      },
      "outputs": [],
      "source": [
        "import missingno as msno\n",
        "\n",
        "msno.bar(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccjATbfBARqZ"
      },
      "outputs": [],
      "source": [
        "msno.bar(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_R9nq0GEe4a"
      },
      "source": [
        "**CATEGORICAL VALUES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQCSc5isPPw0"
      },
      "outputs": [],
      "source": [
        "cat_cols = X_train.select_dtypes(include='category').columns\n",
        "cat_cols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdTVu9QNCR10"
      },
      "source": [
        "**NOTE**\n",
        "\n",
        "*  As the columns are category data type , and we need to impute Unknown as missing value , we need to introduce that as a category first .\n",
        "\n",
        "*  We can impute values which are already the categories of that column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3z8fiTzLSbu"
      },
      "outputs": [],
      "source": [
        "# Step 1: Add 'Unknown' as a new category only if it's not already present\n",
        "X_train[cat_cols] = X_train[cat_cols].apply(lambda col: col.cat.add_categories('Unknown') if 'Unknown' not in col.cat.categories else col)\n",
        "\n",
        "# Step 2: Fill the missing values with 'Unknown'\n",
        "X_train[cat_cols] = X_train[cat_cols].fillna('Unknown')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHBxNBRoNqjs"
      },
      "outputs": [],
      "source": [
        "X_train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzPfhNRYq4m5"
      },
      "source": [
        "**NOTE**\n",
        "\n",
        "If the same column have unknown , N/A values --> change to a common name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoOnvMrGP59v"
      },
      "outputs": [],
      "source": [
        "X_train.replace(['na','N/A','unknown'], 'Unknown', inplace=True)\n",
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmSJN6lKo1ez"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYuRVCUqrj7S"
      },
      "outputs": [],
      "source": [
        "X_test[cat_cols] = X_test[cat_cols].apply(lambda col: col.cat.add_categories('Unknown') if 'Unknown' not in col.cat.categories else col)\n",
        "\n",
        "X_test[cat_cols] = X_test[cat_cols].fillna('Unknown')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEnPVogiD6_W"
      },
      "outputs": [],
      "source": [
        "X_test.replace(['na','N/A','unknown'], 'Unknown', inplace=True)\n",
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jucyxqm4rtIB"
      },
      "outputs": [],
      "source": [
        "for col in cat_cols:\n",
        "  print(X_test[col].value_counts())\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTSBKX9Wr9Rp"
      },
      "outputs": [],
      "source": [
        "X_test.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL63rnU9sYfx"
      },
      "source": [
        "NOTE\n",
        "\n",
        "By observing , the column Casualty_severity has numerical and missing values only , so we can change the entire column to numeric .\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Dhi0tqmsKpR"
      },
      "outputs": [],
      "source": [
        "X_train['Casualty_severity'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnRzjlG-H8F5"
      },
      "source": [
        "**NOTE**\n",
        "\n",
        "Use  --> to_numeric() if the column has missing/unknown values and you have to impute by any methods or use astype() for basic conversions.\n",
        "\n",
        "we cant impute any values in unknown , so I label them as 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6jmyJwbGzaF"
      },
      "outputs": [],
      "source": [
        "X_train['Casualty_severity'].replace('Unknown' , '0' , inplace=True)\n",
        "X_test['Casualty_severity'].replace('Unknown' , '0' , inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3llMaMcJrz8"
      },
      "source": [
        "**NOTE**\n",
        "\n",
        "The warning is because I changed the 'Unknown' category to 0 , so if you want change the name of the category itself , use the above said method\n",
        "\n",
        "Here , the column is changed to int , so I dont worry about categories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdGGEJlPHoCT"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3dDU2exHs5M"
      },
      "outputs": [],
      "source": [
        "X_train['Casualty_severity'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXRIz4eBvWwY"
      },
      "outputs": [],
      "source": [
        "X_train['Casualty_severity'] = X_train['Casualty_severity'].astype('int64')\n",
        "X_test['Casualty_severity'] = X_test['Casualty_severity'].astype('int64')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x09ueIuoG_I9"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIuZN7npSe_H"
      },
      "outputs": [],
      "source": [
        "X_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qDeLSQVvLaQ"
      },
      "outputs": [],
      "source": [
        "X_test.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmqiWUG2T9yK"
      },
      "source": [
        "**NUMERICAL VALUES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M19eKPJr1WoN"
      },
      "outputs": [],
      "source": [
        "num_cols = X_train.select_dtypes(include= int ).columns\n",
        "num_cols\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rn4Xfex19Nl"
      },
      "outputs": [],
      "source": [
        "for col in num_cols:\n",
        "  print(f\"{col} - \",X_train[col].isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WEnV7errjBi"
      },
      "source": [
        "# **FINDING AND HANDLING OUTLIERS**\n",
        "\n",
        "As this dataset has no absurd values , we just mark the outliers rather that removing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l48FX0gIrTCV"
      },
      "outputs": [],
      "source": [
        "num_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssFu9fjMuTgN"
      },
      "outputs": [],
      "source": [
        "for col in num_cols:\n",
        "  sns.boxplot(data=X_train, y=col)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdRSsHzMuYxS"
      },
      "outputs": [],
      "source": [
        "for col in num_cols:\n",
        "  print(X_train[col].value_counts())\n",
        "  print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fZBgayDuqvc"
      },
      "outputs": [],
      "source": [
        "X_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3F8cPufwvBvr"
      },
      "outputs": [],
      "source": [
        "X_test.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1sbEuHWLRMk"
      },
      "outputs": [],
      "source": [
        "Q1 = X_train[num_cols].quantile(0.25)\n",
        "Q3 = X_train[num_cols].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "print(IQR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEZ5Eu80MCge"
      },
      "outputs": [],
      "source": [
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "\n",
        "outliers = ((X_train[num_cols] < lower_bound) | (X_train[num_cols] > upper_bound))\n",
        "\n",
        "print(outliers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0n--pV0cyZYO"
      },
      "outputs": [],
      "source": [
        "outliers_ = ((X_test[num_cols] < lower_bound) | (X_test[num_cols] > upper_bound))\n",
        "print(outliers_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prHJMrvhP290"
      },
      "outputs": [],
      "source": [
        "print(lower_bound)\n",
        "print(upper_bound)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2yfyxi0xjcX"
      },
      "outputs": [],
      "source": [
        "lower_bound['Number_of_vehicles_involved']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvt-6nnnR73l"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbhmROGBt8R4"
      },
      "outputs": [],
      "source": [
        "for col in num_cols:\n",
        "  X_train[f'{col}_flag_outliers'] = np.where((X_train[col] < lower_bound[col]) | (X_train[col] > upper_bound[col]), 1, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nA24tAiZxNC9"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyFgdqesxtcn"
      },
      "outputs": [],
      "source": [
        "for col in num_cols:\n",
        "  X_test[f'{col}_flag_outliers'] = np.where((X_test[col] < lower_bound[col]) | (X_test[col] > upper_bound[col]), 1, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ma_r_WhyPb3"
      },
      "outputs": [],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKlgSjpdzRiG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGjTMZlk0J4W"
      },
      "source": [
        "# **CATEGORICAL VARIABLE ENCODING**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rx4KaNCm0Qrt"
      },
      "outputs": [],
      "source": [
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTV6W8nCMvEy"
      },
      "source": [
        "ENCODING THE TARGET VARIABLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdH5aOYgO4UU"
      },
      "outputs": [],
      "source": [
        "y_test.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umMZe8uqO-mM"
      },
      "outputs": [],
      "source": [
        "Accident_severity_mapping = {'Slight Injury' : 0 , 'Serious Injury' : 1 , 'Fatal injury' : 2}\n",
        "y_train = y_train.map(Accident_severity_mapping)\n",
        "y_test = y_test.map(Accident_severity_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDvTd6yCQnZj"
      },
      "outputs": [],
      "source": [
        "y_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnh-CAbnQpsn"
      },
      "outputs": [],
      "source": [
        "y_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3T_xybyRBkg"
      },
      "outputs": [],
      "source": [
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8gbxhHoR0Fm"
      },
      "outputs": [],
      "source": [
        "cat_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUwEsRvBR9yP"
      },
      "outputs": [],
      "source": [
        "for col in cat_cols:\n",
        "  print(X_train[col].value_counts())\n",
        "  print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1rN7tepSKF7"
      },
      "outputs": [],
      "source": [
        "Age_band_of_driver_mappling = {\n",
        "    'Under 18': 1,\n",
        "    '18-30': 2,\n",
        "    '31-50': 3,\n",
        "    'Over 51': 4,\n",
        "    'Unknown': 5\n",
        "}\n",
        "\n",
        "X_train['Age_band_of_driver'] = X_train['Age_band_of_driver'].map(Age_band_of_driver_mappling)\n",
        "X_test['Age_band_of_driver'] = X_test['Age_band_of_driver'].map(Age_band_of_driver_mappling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yKGKoTFTuq_"
      },
      "outputs": [],
      "source": [
        "X_train['Age_band_of_driver'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naL0FgO4UZXR"
      },
      "outputs": [],
      "source": [
        "Service_year_of_vehicle_mapping = {\n",
        "    'Below 1yr': 1,\n",
        "    '1-2yr': 2,\n",
        "    '2-5yrs': 3,\n",
        "    '5-10yrs': 4,\n",
        "    'Above 10yr': 5,\n",
        "    'Unknown': 6\n",
        "}\n",
        "\n",
        "X_train['Service_year_of_vehicle'] = X_train['Service_year_of_vehicle'].map(Service_year_of_vehicle_mapping)\n",
        "X_test['Service_year_of_vehicle'] = X_test['Service_year_of_vehicle'].map(Service_year_of_vehicle_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4yDCv7RVNMn"
      },
      "outputs": [],
      "source": [
        "X_train['Service_year_of_vehicle'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfErrxy_aiHP"
      },
      "outputs": [],
      "source": [
        "# Mapping for ordinal encoding\n",
        "Age_band_of_casualty_mapping = {\n",
        "    'Unknown': 0,      # Assuming Unknown is the lowest\n",
        "    'Under 18': 1,\n",
        "    '18-30': 2,\n",
        "    '31-50': 3,\n",
        "    'Over 51': 4,\n",
        "    '5': 5             # Assuming '5' refers to a specific age band, possibly a mistake. Make sure this is correct.\n",
        "}\n",
        "\n",
        "\n",
        "X_train['Age_band_of_casualty'] = X_train['Age_band_of_casualty'].map(Age_band_of_casualty_mapping)\n",
        "X_test['Age_band_of_casualty'] = X_test['Age_band_of_casualty'].map(Age_band_of_casualty_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryPVWpZwasPY"
      },
      "outputs": [],
      "source": [
        "X_train['Age_band_of_casualty'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvmOghnwWNsN"
      },
      "outputs": [],
      "source": [
        "X_train['Area_accident_occured'].replace('  Recreational areas' ,  'Recreational areas' , inplace=True)\n",
        "X_test['Area_accident_occured'].replace('  Recreational areas' ,  'Recreational areas' , inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7K2DI2-EC_N"
      },
      "outputs": [],
      "source": [
        "X_train['Fitness_of_casuality'].replace('NormalNormal' , 'Normal' , inplace = True )\n",
        "X_test['Fitness_of_casuality'].replace('NormalNormal' , 'Normal' , inplace = True )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdTiW7MoSiLS"
      },
      "outputs": [],
      "source": [
        "exclude_cols = ['Age_band_of_driver', 'Service_year_of_vehicle' , 'Age_band_of_casualty']   # ordinally encoded already\n",
        "\n",
        "# Select categorical columns and exclude specified ones\n",
        "categorical_cols = X_train.select_dtypes(include=['category']).columns.difference(exclude_cols).tolist()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PctXwnVTYsU5"
      },
      "outputs": [],
      "source": [
        "categorical_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BziuGNuCTTD1"
      },
      "outputs": [],
      "source": [
        "for col in categorical_cols:\n",
        "  print(X_train[col].value_counts())\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ni81yA0LmdSC"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bjPLtAlCTYsQ"
      },
      "outputs": [],
      "source": [
        "for col in categorical_cols:\n",
        "  encoder = ce.TargetEncoder(cols= col , handle_unknown='value', handle_missing='value', verbose=True )\n",
        "\n",
        "  X_train_encoded = encoder.fit_transform(X_train[col], y_train)\n",
        "\n",
        "  X_test_encoded = encoder.transform(X_test[col])\n",
        "\n",
        "  X_train[col] = X_train_encoded\n",
        "\n",
        "  X_test[col] = X_test_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9yjLuM2TcKdh"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cFNH-bNSlqdZ"
      },
      "outputs": [],
      "source": [
        "X_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dcB0b4UZm5QG"
      },
      "outputs": [],
      "source": [
        "exclude_cols = ['Age_band_of_driver', 'Service_year_of_vehicle' , 'Age_band_of_casualty']\n",
        "\n",
        "for col in exclude_cols:\n",
        "  X_train[col] = X_train[col].astype(int)\n",
        "  X_test[col] = X_test[col].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PlqNBi4_n9-c"
      },
      "outputs": [],
      "source": [
        "X_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "whIJ9Pqbn_7F"
      },
      "outputs": [],
      "source": [
        "X_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "q9tDAc4roJul"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcfiv2f-oO5E"
      },
      "source": [
        "RESAMPLING\n",
        "\n",
        "It’s crucial to only apply SMOTE on the training set. The test set should remain untouched to accurately evaluate your model's performance on data that reflects the original class distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2yjg4G6522kA"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ukmp04cr3NQy"
      },
      "outputs": [],
      "source": [
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "q14gSLfV3plu"
      },
      "outputs": [],
      "source": [
        "y_train_resampled.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK3iVREqDut_"
      },
      "source": [
        "# **FEATURE SCALING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LESAiOXs7-Jr"
      },
      "outputs": [],
      "source": [
        "X_train_resampled.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-g0pyzgKFGwR"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "# 2. Fit on X_train and transform both X_train and X_test\n",
        "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5fSeRAudGRnD"
      },
      "outputs": [],
      "source": [
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train_resampled.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j-f6EfqXGeAk"
      },
      "outputs": [],
      "source": [
        "X_train_scaled.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nl4dIve_HUgK"
      },
      "outputs": [],
      "source": [
        "logreg_ovr = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=1000 )\n",
        "\n",
        "# Fit the model on the resampled training data\n",
        "logreg_ovr.fit(X_train_scaled, y_train_resampled)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = logreg_ovr.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Classification Report:')\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-YMS5zaxwtZf"
      },
      "outputs": [],
      "source": [
        "dt_model = DecisionTreeClassifier()\n",
        "# Fit the model on the training data\n",
        "dt_model.fit(X_train_scaled, y_train_resampled)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = dt_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Classification Report:')\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtX8x0Oe7mdh"
      },
      "source": [
        "**NOTE**\n",
        "\n",
        " By default, decision trees use the Gini impurity as the criterion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Xb3larbx1O_E"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_classifier.fit(X_train_scaled, y_train_resampled)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = rf_classifier.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "r11_4dEu1YPb"
      },
      "outputs": [],
      "source": [
        "# Reinitialize RandomForestClassifier with balanced class weights\n",
        "rf_classifier = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "\n",
        "# Train the model\n",
        "rf_classifier.fit(X_train_scaled, y_train_resampled)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = rf_classifier.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, zero_division=0)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HsBvuPEl2HUO"
      },
      "outputs": [],
      "source": [
        "y_test.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "r20-Yd-w2Tpf"
      },
      "outputs": [],
      "source": [
        "# Initialize the SVC model\n",
        "svc_model = SVC(kernel='rbf')  # You can change the kernel to 'rbf','linear' , 'poly' ,or others depending on your need\n",
        "\n",
        "# Train the model on the resampled training data\n",
        "svc_model.fit(X_train_scaled, y_train_resampled)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = svc_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tkWsp2aBnYcW"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create the AdaBoost classifier\n",
        "adaboost_clf = AdaBoostClassifier(n_estimators=100, random_state=42)   # estimators ->  specifies the number of weak classifiers (decision stumps) to use.\n",
        "\n",
        "# Fit the model to the training data\n",
        "adaboost_clf.fit(X_train_scaled, y_train_resampled)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = adaboost_clf.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "print(\"\\nClassification Report (Test Data):\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UawvvSTYoqDF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create the k-NN classifier with 'distance' weights\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=10, weights='distance', metric='manhattan')  # Distance metric can be [ euclidean , manhattan etc ]\n",
        "\n",
        "# Fit the model to the training data\n",
        "knn_clf.fit(X_train_scaled, y_train_resampled)\n",
        "\n",
        "# Make predictions\n",
        "\n",
        "y_pred_test = knn_clf.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "print(\"\\nClassification Report (Test Data):\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "\n",
        "# weights is how you treat the k-neighbors to get maximum votes , 'distance' gives more weights for nearest neighbors [uniform , distance  etc ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M3x8o3sXcQVV"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "# Create the XGBoost classifier\n",
        "xgb_clf = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "xgb_clf.fit(X_train_scaled, y_train_resampled)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_test = xgb_clf.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "print(\"\\nClassification Report (Test Data):\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxr6o0cbseIF"
      },
      "source": [
        "# **TUNING HYPER PARAMETERS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IeHn9sP628kq"
      },
      "outputs": [],
      "source": [
        "'''from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Define the Random Forest model\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define the hyperparameters grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],  # Number of trees\n",
        "    'max_depth': [None, 10, 20, 30],  # Maximum tree depth\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum samples to split a node\n",
        "    'min_samples_leaf': [1, 2, 4],    # Minimum samples at leaf nodes\n",
        "    'max_features': ['sqrt', 'log2'], # Number of features to consider for best split\n",
        "}\n",
        "\n",
        "# Set up the GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf_clf,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',  # Use accuracy as the evaluation metric\n",
        "    cv=5,                # 5-fold cross-validation\n",
        "    verbose=2,           # Higher number for more detailed output\n",
        "    n_jobs=-1            # Use all processors\n",
        ")\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search.fit(X_train_scaled, y_train_resampled)\n",
        "\n",
        "# Get the best parameters and best score\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate on the test set\n",
        "best_rf_clf = grid_search.best_estimator_           -> best estimator -> stores the best model with high performance from the searching we done .\n",
        "y_pred_test = best_rf_clf.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
        "print(\"\\nClassification Report (Test Data):\")\n",
        "print(classification_report(y_test, y_pred_test))   '''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ffmma3XOm2ZU"
      },
      "outputs": [],
      "source": [
        "'''from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Define the model\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define the parameter grid with ranges\n",
        "param_dist = {\n",
        "    'n_estimators': [int(x) for x in np.linspace(start=100, stop=500, num=5)],  # Number of trees\n",
        "    'max_depth': [None] + [int(x) for x in np.linspace(10, 50, num=5)],         # Tree depth\n",
        "    'max_features': ['sqrt', 'log2', None],                                    # Max features to consider\n",
        "    'bootstrap': [True, False]                                                 # Use bootstrap sampling\n",
        "}\n",
        "\n",
        "# Set up RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=rf_clf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter= 10 ,                 # Number of parameter settings to sample\n",
        "    scoring='accuracy',        # Metric to optimize\n",
        "    cv=3,                      # 3-fold cross-validation\n",
        "    verbose=2,                 # Higher value for detailed output\n",
        "    random_state=42,           # Ensure reproducibility\n",
        "    n_jobs=-1                  # Use all processors\n",
        ")\n",
        "\n",
        "# Perform the random search\n",
        "random_search.fit(X_train_scaled, y_train_resampled)\n",
        "\n",
        "# Access the best model and parameters\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", random_search.best_score_)\n",
        "\n",
        "# Evaluate on test data\n",
        "best_rf_clf = random_search.best_estimator_\n",
        "y_pred_test = best_rf_clf.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
        "print(\"\\nClassification Report (Test Data):\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xAvP_GPBFCn6"
      },
      "outputs": [],
      "source": [
        "# Define the objective function\n",
        "'''def objective(trial):\n",
        "    # Suggest hyperparameters for optimization\n",
        "    n_estimators = trial.suggest_int('n_estimators', 100, 500)  # Number of trees\n",
        "    max_depth = trial.suggest_int('max_depth', 10, 50)          # Max depth of trees\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)\n",
        "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
        "    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
        "\n",
        "    # Create the model with suggested hyperparameters\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        max_features=max_features,\n",
        "        bootstrap=bootstrap,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Cross-validation to evaluate performance\n",
        "    score = cross_val_score(model, X_train_scaled, y_train_resampled, cv=2 , scoring='accuracy').mean()\n",
        "    return score\n",
        "\n",
        "\n",
        "\n",
        "# Create a study and optimize\n",
        "study = optuna.create_study(direction='maximize')  # Maximize accuracy\n",
        "study.optimize(objective, n_trials=10, timeout= 180)  # 10 trials or 3 minutes [if trial is started within time limit -> it finishes the trial even if limit is reached ]\n",
        "\n",
        "# Best hyperparameters and score\n",
        "print(\"Best Hyperparameters:\", study.best_params)\n",
        "print(\"Best Cross-Validation Score:\", study.best_value)\n",
        "\n",
        "# Train and evaluate the best model\n",
        "best_params = study.best_params\n",
        "best_model = RandomForestClassifier(**best_params, random_state=42)   # best_estimator_ is not available as gridsearchCV , ** to unpack the dictionary and set the corresponding values\n",
        "best_model.fit(X_train_scaled, y_train_resampled)\n",
        "\n",
        "y_pred_test = best_model.predict(X_test_scaled)\n",
        "print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
        "print(\"\\nClassification Report (Test Data):\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "\n",
        "# optuna automatically gives detailed info as below\n",
        "\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m7oOuCZMF4mm"
      },
      "outputs": [],
      "source": [
        "'''# Define the objective function\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 1),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "    }\n",
        "\n",
        "    # Create and evaluate the model\n",
        "    model = XGBClassifier(**params)  # Pass params using unpacking\n",
        "    score = cross_val_score(model, X_train_scaled, y_train_resampled, cv=3, scoring='accuracy').mean()\n",
        "    return score\n",
        "\n",
        "# Create an Optuna study\n",
        "study = optuna.create_study(direction='maximize')  # Maximize accuracy\n",
        "study.optimize(objective, n_trials=20, timeout=300)  # Run for 50 trials or 5 minutes\n",
        "\n",
        "# Display best hyperparameters and score\n",
        "print(\"Best Hyperparameters:\", study.best_params)\n",
        "print(\"Best Cross-Validation Score:\", study.best_value)\n",
        "\n",
        "# Train the model with the best hyperparameters\n",
        "best_model = XGBClassifier(**study.best_params, random_state=42)\n",
        "best_model.fit(X_train_scaled, y_train_resampled)\n",
        "\n",
        "# Test the model\n",
        "y_pred_test = best_model.predict(X_test_scaled)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nTest Accuracy:\", test_accuracy)\n",
        "print(\"\\nClassification Report (Test Data):\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4ditIBhwGXb"
      },
      "source": [
        "PROVIDING CLASS WEIGHTS WITHOUT SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "44TGowIMpjA1"
      },
      "outputs": [],
      "source": [
        "'''def objective(trial):\n",
        "    # Suggest hyperparameters for the Random Forest model\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
        "    max_depth = trial.suggest_int('max_depth', 5, 30)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)\n",
        "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
        "    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
        "\n",
        "    # Tune class weights\n",
        "    class_weight = trial.suggest_categorical(\n",
        "        'class_weight',\n",
        "        ['balanced', 'balanced_subsample']  # Example custom weights\n",
        "    )\n",
        "\n",
        "    # Create the Random Forest model\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        max_features=max_features,\n",
        "        bootstrap=bootstrap,\n",
        "        class_weight=class_weight,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Evaluate using cross-validation\n",
        "    score = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy').mean()\n",
        "    return score\n",
        "\n",
        "# Create a study and optimize\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=10, timeout=300)  # Run 10 trials or 5 minutes\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", study.best_params)\n",
        "\n",
        "# Train the best model on the entire training set\n",
        "best_params = study.best_params\n",
        "best_model = RandomForestClassifier(**best_params, random_state=42)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_test = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "print(\"\\nTest Accuracy:\", test_accuracy)\n",
        "print(\"\\nClassification Report (Test Data):\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3UPjSVuTwbFd"
      },
      "outputs": [],
      "source": [
        "y_test.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN4PgwyLzTQM"
      },
      "source": [
        "for xgboost , we can use scale_pos_weight and sample weight for managing imbalance\n",
        "\n",
        "scalepos_weight is for binary classification\n",
        "I have used sample weight here  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi3S11gT0Mxu"
      },
      "source": [
        "we usually do not tune sample weight , we only tune scale_pos_weight to provide more importance to positive class\n",
        "\n",
        "sample weight =  totalsample / number of samples in each class i\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PPhLIuaW6M5o"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Calculate class weights\n",
        "class_counts = np.bincount(y_train)  # Count samples per class\n",
        "total_samples = len(y_train)\n",
        "class_weights = {i: total_samples / class_counts[i] for i in range(len(class_counts))}\n",
        "\n",
        "# Assign sample weights\n",
        "sample_weights = np.array([class_weights[label] for label in y_train])\n",
        "\n",
        "\n",
        "# Define the objective function\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "    }\n",
        "\n",
        "    # Create and evaluate the model\n",
        "    model = XGBClassifier(**params)  # Pass params using unpacking\n",
        "    score = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy' ,params={'sample_weight': sample_weights}).mean()\n",
        "    return score                                                                # handle same class imbalance in cv too ^\n",
        "\n",
        "# Create an Optuna study\n",
        "study = optuna.create_study(direction='maximize')  # Maximize accuracy\n",
        "study.optimize(objective, n_trials=20, timeout=300)  # Run for 50 trials or 5 minutes\n",
        "\n",
        "# Display best hyperparameters and score\n",
        "print(\"Best Hyperparameters:\", study.best_params)\n",
        "print(\"Best Cross-Validation Score:\", study.best_value)\n",
        "\n",
        "# Train the model with the best hyperparameters\n",
        "best_model_XGB = XGBClassifier(**study.best_params, random_state=42)\n",
        "best_model_XGB.fit(X_train, y_train ,sample_weight=sample_weights)\n",
        "\n",
        "# Test the model\n",
        "y_pred_test = best_model_XGB.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nTest Accuracy:\", test_accuracy)\n",
        "print(\"\\nClassification Report (Test Data):\")\n",
        "print(classification_report(y_test, y_pred_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqAiNvujDjTQ"
      },
      "source": [
        "# **EXPLAINABLE AI**\n",
        "\n",
        "[currenly working on this , I'll update this soon !]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "po9Xc2lmEMV2"
      },
      "outputs": [],
      "source": [
        "feature_importance = best_model_XGB.feature_importances_\n",
        "\n",
        "# Get feature names directly from X_train\n",
        "feature_names = X_train.columns  # X_train is assumed to be a pandas DataFrame\n",
        "\n",
        "# Sort features by importance\n",
        "indices = np.argsort(feature_importance)[::-1]  # Sort in descending order\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.bar(range(len(feature_importance)), feature_importance[indices], align=\"center\", color=\"skyblue\")\n",
        "plt.xticks(range(len(feature_importance)), [feature_names[i] for i in indices], rotation=90)\n",
        "plt.xlabel(\"Feature Names\")\n",
        "plt.ylabel(\"Importance Score\")\n",
        "plt.tight_layout()  # Adjust layout to fit feature names properly\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QxwpAvd-HCvm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YQw4ob9Y0jHO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WDVCr9cx5C0z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}